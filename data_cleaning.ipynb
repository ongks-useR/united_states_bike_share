{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_cleaning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1v2xOtI6QUgWYc1QxBFFiiGStjgJLzKuv",
      "authorship_tag": "ABX9TyPyqW2/0DrWUGTk6kAnhp6u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ongks-useR/united_states_bike_share/blob/main/data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix5AJrRDbTEg"
      },
      "source": [
        "# ***Bike Sharing in New York, U.S 2019***\n",
        "\n",
        "This is part of my journey towards mastering Python for Data Science.\n",
        "\n",
        "I use United States bike sharing data (particularly New York City) for data cleaning; please visit [bikeshare.com](https://www.bikeshare.com/data/) for data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOmJOktQeYKB"
      },
      "source": [
        "# install haversine\n",
        "# https://pypi.org/project/haversine/ >> to calculate distance between geometry coordinates\n",
        "\n",
        "pip install haversine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxWaDwZ_dftE"
      },
      "source": [
        "## Python Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXTSfOOEdAsn"
      },
      "source": [
        "# data analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "# functional loop\n",
        "from functools import reduce\n",
        "\n",
        "# Operating System\n",
        "from glob import glob\n",
        "from os import path\n",
        "from pathlib import Path\n",
        "\n",
        "# calculate distance between geo coordinates\n",
        "from haversine import haversine_vector, Unit"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzV01uqjm43z"
      },
      "source": [
        "## ***Lesson 01: Import CSV, efficiently***\n",
        "\n",
        "After trials & errors, I find out various ways of import CSV, specifically multiple CSV files. Most of the courses will teach *Pandas read_csv()* method for single file, and usually the file size is small for education purpose..\n",
        "\n",
        "However, in reality, an analyst might has to gather multipe CSV files which each file could be huge in size. In this case, bike sharing monthly file is 100 MB+. We will need to analyze 12-month worth of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DacR_O_brDCF",
        "outputId": "0ce0889a-faba-43ad-ba12-8884cc01a957"
      },
      "source": [
        "# list files available in the 'New York Bike Share' directory\n",
        "\n",
        "!ls /content/drive/MyDrive/'New York Bike Share'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201901-citibike-tripdata.csv  201908-citibike-tripdata.csv\n",
            "201902-citibike-tripdata.csv  201909-citibike-tripdata.csv\n",
            "201903-citibike-tripdata.csv  201910-citibike-tripdata.csv\n",
            "201904-citibike-tripdata.csv  201911-citibike-tripdata.csv\n",
            "201905-citibike-tripdata.csv  201912-citibike-tripdata.csv\n",
            "201906-citibike-tripdata.csv  new_york_bikeshare_2019.csv\n",
            "201907-citibike-tripdata.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km-Zbfyehb7j"
      },
      "source": [
        "'''\n",
        "For demo only...\n",
        "\n",
        "Method 1: Inefficient way ~ ~\n",
        "\n",
        "Result: long and repetitive codes that are error prone.\n",
        "Note: Imagine we have 30 files within the same directory??\n",
        "\n",
        "'''\n",
        "\n",
        "file_01 = pd.read_csv('/content/drive/MyDrive/New York Bike Share/201901-citibike-tripdata.csv')\n",
        "file_02 = pd.read_csv('/content/drive/MyDrive/New York Bike Share/201902-citibike-tripdata.csv')\n",
        "file_03 = pd.read_csv('/content/drive/MyDrive/New York Bike Share/201903-citibike-tripdata.csv')\n",
        "file_04 = pd.read_csv('/content/drive/MyDrive/New York Bike Share/201904-citibike-tripdata.csv')\n",
        "file_05 = pd.read_csv('/content/drive/MyDrive/New York Bike Share/201905-citibike-tripdata.csv')\n",
        "file_06 = pd.read_csv('/content/drive/MyDrive/New York Bike Share/201906-citibike-tripdata.csv')\n",
        "\n",
        "df = pd.concat([file_01, file_02, file_03], ignore_index=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmP6Fod_i-Zb",
        "outputId": "c31c6c7b-eb0e-45e9-c121-25a46d00a314"
      },
      "source": [
        "'''\n",
        "Method 2: Efficient way ~ ~\n",
        "\n",
        "Step 1: Getting file names within directory that are required for analysis\n",
        "\n",
        "'''\n",
        "\n",
        "# current path of working directory for jupyter notebook and CSV files in Google Colab\n",
        "file_dir = '/content/drive/MyDrive/New York Bike Share'\n",
        "\n",
        "# getting file names within the directory and sort file name\n",
        "file_names = glob(path.join(file_dir, '*-citibike-tripdata.csv'))\n",
        "file_names"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/New York Bike Share/201901-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201902-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201903-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201904-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201905-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201906-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201907-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201908-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201909-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201910-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201911-citibike-tripdata.csv',\n",
              " '/content/drive/MyDrive/New York Bike Share/201912-citibike-tripdata.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggU7FxpVs-99",
        "outputId": "fa062bb3-b4d7-47e3-b296-413c15b7202a"
      },
      "source": [
        "# only import 100 line items for quick view of column names and data type\n",
        "\n",
        "pd.read_csv('/content/drive/MyDrive/New York Bike Share/201901-citibike-tripdata.csv', nrows=100).info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 15 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   tripduration             100 non-null    int64  \n",
            " 1   starttime                100 non-null    object \n",
            " 2   stoptime                 100 non-null    object \n",
            " 3   start station id         100 non-null    int64  \n",
            " 4   start station name       100 non-null    object \n",
            " 5   start station latitude   100 non-null    float64\n",
            " 6   start station longitude  100 non-null    float64\n",
            " 7   end station id           100 non-null    int64  \n",
            " 8   end station name         100 non-null    object \n",
            " 9   end station latitude     100 non-null    float64\n",
            " 10  end station longitude    100 non-null    float64\n",
            " 11  bikeid                   100 non-null    int64  \n",
            " 12  usertype                 100 non-null    object \n",
            " 13  birth year               100 non-null    int64  \n",
            " 14  gender                   100 non-null    int64  \n",
            "dtypes: float64(4), int64(6), object(5)\n",
            "memory usage: 11.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aWkUQAXrmTW"
      },
      "source": [
        "'''\n",
        "Method 2: Efficient way ~ ~\n",
        "\n",
        "Step 2: Define function to create Pandas DataFrame\n",
        "\n",
        "'''\n",
        "\n",
        "col_index = [0, 1, 5, 6, 9 ,10, 12, 13, 14]\n",
        "\n",
        "col_name = ['duration', \n",
        "            'time_start', \n",
        "            'station_latitude_start', \n",
        "            'station_longitude_start',\n",
        "            'station_latitude_end', \n",
        "            'station_longitude_end', \n",
        "            'user_type', \n",
        "            'birth_year', \n",
        "            'gender']\n",
        "\n",
        "col_type = {\n",
        "    'duration': np.int32,\n",
        "    'station_latitude_start': np.float32,\n",
        "    'station_longitude_start': np.float32,\n",
        "    'station_latitude_end': np.float32,\n",
        "    'station_longitude_end': np.float32,\n",
        "    'user_type': 'category',\n",
        "    'birth_year': 'object',\n",
        "    'gender': 'category'\n",
        "}\n",
        "\n",
        "# self defined function to create dataframe\n",
        "def create_df(f, size = 100_000):\n",
        "\n",
        "    # create chunks of data frame with 100K per chunk. Result is an iteratable of dataframes\n",
        "    result = pd.read_csv(f, chunksize=size, usecols=col_index, names=col_name, dtype=col_type, parse_dates=['time_start'], header=0)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvoH9xIeub6o",
        "outputId": "f9a85674-a0e0-4a66-9eff-c50ad102dd0b"
      },
      "source": [
        "'''\n",
        "Method 2: Efficient way ~ ~\n",
        "\n",
        "Step 3: Use .map() to apply 'create_df' function to each file in 'file_names'\n",
        "\n",
        "'''\n",
        "\n",
        "# .map() will apply 'create_df' function to each file in file_names\n",
        "# result is list of iteratable. Each iterable contains many dataframes with 100,000 rows\n",
        "\n",
        "df = list(map(create_df, file_names))\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<pandas.io.parsers.TextFileReader at 0x7fbb63678090>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb636757d0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb63675890>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb636784d0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb636786d0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb636788d0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb63678ad0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb63678cd0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb63678ed0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb63678fd0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb63678dd0>,\n",
              " <pandas.io.parsers.TextFileReader at 0x7fbb747a9910>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aoH3euSvL5q",
        "outputId": "fea4c306-85b9-46ae-afed-7a397d65641c"
      },
      "source": [
        "'''\n",
        "Method 2: Efficient way ~ ~\n",
        "\n",
        "Step 4: apply python 'list comprehension' to get list of DataFrame\n",
        "\n",
        "'''\n",
        "\n",
        "# loop through each iteratable and store each dataframe to list with 'list comprehension'\n",
        "\n",
        "df = [chunk for ls in df for chunk in ls]\n",
        "\n",
        "# let's check one of the dataframe\n",
        "# each dataframe contains up to 100,000 line items\n",
        "df[0].info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                   Non-Null Count   Dtype         \n",
            "---  ------                   --------------   -----         \n",
            " 0   duration                 100000 non-null  int32         \n",
            " 1   time_start               100000 non-null  datetime64[ns]\n",
            " 2   station_latitude_start   100000 non-null  float32       \n",
            " 3   station_longitude_start  100000 non-null  float32       \n",
            " 4   station_latitude_end     100000 non-null  float32       \n",
            " 5   station_longitude_end    100000 non-null  float32       \n",
            " 6   user_type                100000 non-null  category      \n",
            " 7   birth_year               100000 non-null  object        \n",
            " 8   gender                   100000 non-null  category      \n",
            "dtypes: category(2), datetime64[ns](1), float32(4), int32(1), object(1)\n",
            "memory usage: 3.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYXXk7V4zn-y",
        "outputId": "b7be4371-2c00-46b9-f81e-3fdb55625314"
      },
      "source": [
        "# df[1] index number range from 100,000 to 199,999\n",
        "\n",
        "df[1].info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 100000 to 199999\n",
            "Data columns (total 9 columns):\n",
            " #   Column                   Non-Null Count   Dtype         \n",
            "---  ------                   --------------   -----         \n",
            " 0   duration                 100000 non-null  int32         \n",
            " 1   time_start               100000 non-null  datetime64[ns]\n",
            " 2   station_latitude_start   100000 non-null  float32       \n",
            " 3   station_longitude_start  100000 non-null  float32       \n",
            " 4   station_latitude_end     100000 non-null  float32       \n",
            " 5   station_longitude_end    100000 non-null  float32       \n",
            " 6   user_type                100000 non-null  category      \n",
            " 7   birth_year               100000 non-null  object        \n",
            " 8   gender                   100000 non-null  category      \n",
            "dtypes: category(2), datetime64[ns](1), float32(4), int32(1), object(1)\n",
            "memory usage: 3.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfB2Un48yba6",
        "outputId": "af3c7002-98f2-481e-a72f-2e4afbceb2e6"
      },
      "source": [
        "'''\n",
        "Method 2: Efficient way ~ ~\n",
        "\n",
        "Step 5: use pd.concat() to merge list of dataframes\n",
        "\n",
        "'''\n",
        "\n",
        "# p.concat() >> append list of dataframe on top of each other to produce master dataframe\n",
        "# note: each dataframe has different index number. parameter 'ignore_index' is set to 'True' and pd.concat() will reset index number after merge.\n",
        "\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20551697 entries, 0 to 20551696\n",
            "Data columns (total 9 columns):\n",
            " #   Column                   Dtype         \n",
            "---  ------                   -----         \n",
            " 0   duration                 int32         \n",
            " 1   time_start               datetime64[ns]\n",
            " 2   station_latitude_start   float32       \n",
            " 3   station_longitude_start  float32       \n",
            " 4   station_latitude_end     float32       \n",
            " 5   station_longitude_end    float32       \n",
            " 6   user_type                category      \n",
            " 7   birth_year               object        \n",
            " 8   gender                   category      \n",
            "dtypes: category(2), datetime64[ns](1), float32(4), int32(1), object(1)\n",
            "memory usage: 744.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk4_O7R10DOn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}